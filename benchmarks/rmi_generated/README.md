# RMI (Recursive Model Index) Generated Code

This directory contains C++ code generated by the [RMI compiler](https://github.com/learnedsystems/RMI) for comparison benchmarks with JazzyIndex.

## Prerequisites

1. **Install Rust and Cargo**: Visit https://rustup.rs/
2. **Build the RMI compiler**:
   ```bash
   cd external/RMI
   cargo build --release
   ```

## Generating RMI Code for Datasets

The RMI compiler takes a binary dataset and generates optimized C++ code for searching it.

### Obtaining Datasets

The 200M datasets are available from the [Harvard Dataverse](https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/JGVF9A):

- books_200M_uint64
- wiki_200M_uint64
- osm_cellids_200M_uint64
- fb_200M_uint64

Download these and place them in `benchmarks/datasets/` directory:

```bash
mkdir -p benchmarks/datasets
# Download datasets from Harvard Dataverse link above
# Place them in benchmarks/datasets/
```

### Dataset Format

RMI expects binary files with this format:
- First 8 bytes: `uint64_t` count of elements (little endian)
- Remaining bytes: sorted `uint64_t` values (little endian)

**Important**: Filenames must end with `_uint64` or `_uint32` to indicate data type.

### Generate RMI Code

For each 200M dataset, run:

```bash
cd external/RMI

# Books dataset
cargo run --release -- ../../benchmarks/datasets/books_200M_uint64 books_rmi linear,linear 100

# Wikipedia dataset
cargo run --release -- ../../benchmarks/datasets/wiki_200M_uint64 wiki_rmi linear,linear 100

# OSM dataset
cargo run --release -- ../../benchmarks/datasets/osm_cellids_200M_uint64 osm_rmi linear,linear 100

# Facebook dataset
cargo run --release -- ../../benchmarks/datasets/fb_200M_uint64 fb_rmi linear,linear 100
```

### Command Explanation

- `../../benchmarks/datasets/books_200M_uint64` - Input dataset path (no extension!)
- `books_rmi` - Output namespace (generates `books_rmi.h` and `books_rmi.cpp`)
- `linear,linear` - Two-layer model: both layers use linear interpolation
- `100` - Branching factor (number of second-layer models)

The RMI compiler will create:
- `books_rmi.h` - Header file with namespace and function declarations
- `books_rmi.cpp` - Implementation file
- `rmi_data/` - Directory containing model parameters (default location)

### Move Generated Files

After generation, move the output files to this directory:

```bash
cd external/RMI
mv books_rmi.h books_rmi.cpp ../../benchmarks/rmi_generated/
mv wiki_rmi.h wiki_rmi.cpp ../../benchmarks/rmi_generated/
mv osm_rmi.h osm_rmi.cpp ../../benchmarks/rmi_generated/
mv fb_rmi.h fb_rmi.cpp ../../benchmarks/rmi_generated/
```

## Building with RMI Benchmarks

Enable RMI benchmarks when configuring CMake:

```bash
cmake -B build -DENABLE_RMI_BENCHMARKS=ON
cmake --build build --target jazzy_index_benchmarks
```

## Running RMI Comparison Benchmarks

Run the 200M benchmarks with RMI comparisons:

```bash
./build/jazzy_index_benchmarks --200m
```

The benchmark output will include:
- `JazzyIndex/<dataset>/S<segments>/N200000000/...` - JazzyIndex lookups
- `RMI/<dataset>/N200000000/...` - RMI lookups
- `LowerBound/<dataset>/N200000000/...` - std::lower_bound baseline

## Tuning RMI Models

You can experiment with different model architectures:

### Model Types
- `linear` - Linear interpolation (fastest, least accurate)
- `linear_spline` - Piecewise linear spline
- `cubic` - Cubic interpolation
- `radix` - Radix-based model

### Example Configurations

```bash
# Two linear layers, 256 second-layer models (more models = higher accuracy, more memory)
cargo run --release -- ../../benchmarks/datasets/books_200M_uint64 books_rmi linear,linear 256

# Three layers with different branching factors
cargo run --release -- ../../benchmarks/datasets/books_200M_uint64 books_rmi linear,linear,linear 10,100

# Cubic interpolation in first layer
cargo run --release -- ../../benchmarks/datasets/books_200M_uint64 books_rmi cubic,linear 100
```

## Benchmark Scenarios

The RMI benchmarks test two scenarios:

1. **FoundMiddle**: Lookup of element at `data[size/2]`
2. **NotFound**: Lookup of value `data[size-1] + 1000`

These match the scenarios used for JazzyIndex benchmarks, enabling direct performance comparison.

## Expected Output

Sample benchmark results comparing RMI vs JazzyIndex:

```
JazzyIndex/Books/S256/N200000000/FoundMiddle    3.2 ns
RMI/books/N200000000/FoundMiddle                4.5 ns
LowerBound/Books/N200000000/FoundMiddle        28.1 ns
```

## Notes

- RMI code is dataset-specific and must be regenerated if datasets change
- Generated RMI files can be large (several MB) for 200M element datasets
- RMI lookup returns position + error bound; you may need exponential search within the error bound
- The RMI compiler optimizes for throughput; JazzyIndex optimizes for latency with quantile segmentation
